{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":7461426,"sourceType":"datasetVersion","datasetId":4342699},{"sourceId":7485073,"sourceType":"datasetVersion","datasetId":4355029}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install seaborn imutils --quiet","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math, random\nimport imutils\nimport os\nimport gc\nfrom tqdm import tqdm\nimport tensorflow as tf\nfrom tensorflow.train import BytesList, Int64List, Feature, Features, Example\nfrom kaggle_datasets import KaggleDatasets\nfrom kaggle_secrets import UserSecretsClient\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frame_cnt = 15\nframe_width = 50\nDEBUG = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TPU_MODE = True\n\nif TPU_MODE:\n    try: # detect TPUs\n        # NEW: in Tensorflow 2.4\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        # instantiate a distribution strategy\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        tpu_strategy = tf.distribute.TPUStrategy(tpu)\n    except ValueError: # otherwise detect GPUs\n        strategy = tf.distribute.MirroredStrategy() # single-GPU or multi-GPU\n    \n    N_REPLICAS = tpu_strategy.num_replicas_in_sync\n    \n    print(f'Running on TPU {tpu.master()}') \nelse:\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print('Device is:',device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and validation data generator","metadata":{}},{"cell_type":"code","source":"# Install this to prevent: ModuleNotFoundError: No module named 'tensorflow_gcs_config'\n!pip install tensorflow-gcs-config","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Need this part to access my own private dataset\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)\n\n# A description of the features.\nfeatures_dict = {\n    'image': tf.io.FixedLenFeature([frame_width*frame_width*frame_cnt], tf.float32),\n    'label': tf.io.FixedLenFeature([2], tf.int64),\n  }\n\nif TPU_MODE:\n    BATCH_SIZE = 16 * N_REPLICAS\nelse:\n    BATCH_SIZE = 32\n\nprint('BATCH SIZE:', BATCH_SIZE)\n\ndef parse_tfrecord(example,visualize = False):\n    sample_record = tf.io.parse_single_example(example,features_dict)\n    feats = sample_record['image']\n    label = sample_record['label']\n    \n    feats = tf.reshape(feats,[frame_cnt,frame_width,frame_width])\n    feats = tf.transpose(feats, [1,2,0]) # in Conv3D we need (h,w,depth)\n    label = tf.reshape(label,[2])\n\n    return feats,label\n\nGCS_PATH = KaggleDatasets().get_gcs_path('bsms155050')\nif DEBUG:\n    print(f\"\\n... IMMEDIATE CONTENTS OF DATA DIRECTORY IS:\")\n    for file in tf.io.gfile.glob(os.path.join(GCS_PATH, \"*\")): print(f\"\\t--> {file}\")\n\ntf_pos_records = tf.io.gfile.glob(GCS_PATH + '/pos/*.tfrecord')\ntf_neg_records = tf.io.gfile.glob(GCS_PATH + '/neg/*.tfrecord')\n\nAUTO = tf.data.experimental.AUTOTUNE\ntf_pos_dataset = tf.data.TFRecordDataset(tf_pos_records, num_parallel_reads=AUTO).map(parse_tfrecord)\ntf_neg_dataset = tf.data.TFRecordDataset(tf_neg_records, num_parallel_reads=AUTO).map(parse_tfrecord)\n\ntf_pos_trn_dataset = tf_pos_dataset.skip(512)\ntf_pos_val_dataset = tf_pos_dataset.take(512)\n\ntf_neg_trn_dataset = tf_neg_dataset.skip(512)\ntf_neg_val_dataset = tf_neg_dataset.take(512)\n\ntf_pos_trn_dataset = tf_pos_trn_dataset.repeat(300).shuffle(BATCH_SIZE*10)\ntf_neg_trn_dataset = tf_neg_trn_dataset.repeat(90).shuffle(BATCH_SIZE*10)\n\n#combined_dataset = tf_pos_dataset.concatenate(tf_neg_dataset).shuffle(BATCH_SIZE*10)\ncombined_trn_dataset = tf.data.Dataset.sample_from_datasets([tf_pos_trn_dataset, tf_neg_trn_dataset], weights=[0.5, 0.5]).batch(BATCH_SIZE)\ncombined_val_dataset = tf.data.Dataset.sample_from_datasets([tf_pos_val_dataset, tf_neg_val_dataset], weights=[0.5, 0.5]).batch(4)\n\n# print('The pos dataset size:',len(list(tf_pos_dataset)))\n# print('The neg dataset size:',len(list(tf_neg_dataset)))\n# print('The final dataset size:',len(list(combined_dataset)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation - let's check if we recorded images and labels correctly.\n\n# Read from file and show\nfilenames = ['/kaggle/input/bsms155050/pos/100147863_0.tfrecord']\nraw_dataset = tf.data.TFRecordDataset(filenames)\n\ndef visualize_images(img_arr,frame_cnt):\n    a = 5\n    b = frame_cnt // a\n\n    fig, axarr = plt.subplots(b, a, constrained_layout = True, figsize=(5, 5))\n\n    for i in range(b):\n        for j in range(a):\n            axarr[i, j].set_xticklabels([])\n            axarr[i, j].set_yticklabels([])\n            axarr[i, j].imshow(img_arr[:,:,i*a+j], cmap='gray')\n    plt.show()\n    \n\nparsed_dataset = raw_dataset.map(parse_tfrecord)\nfor img, label in parsed_dataset:\n    print(img.shape)\n    print(label)\n    visualize_images(img,frame_cnt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras import activations\n\nclass BC3DConvNet(tf.keras.Model):\n    def __init__(self, frame_cnt, frame_width):\n        super(BC3DConvNet, self).__init__()\n\n        self.conv1 = Conv2D(filters=frame_cnt*16, kernel_size=(3, 3), input_shape=(frame_width, frame_width, frame_cnt))\n        self.bn1 = BatchNormalization()\n        self.conv2 = Conv2D(filters=frame_cnt*16, kernel_size=(3, 3))\n        self.bn2 = BatchNormalization()\n        self.conv3 = Conv2D(filters=frame_cnt*32, kernel_size=(3, 3))\n        self.bn3 = BatchNormalization()\n        self.conv4 = Conv2D(filters=frame_cnt*64, kernel_size=(3, 3))\n        self.bn4 = BatchNormalization()\n\n        # Calculate the convolution's output size:\n        tmp = np.zeros((1, frame_width, frame_width, frame_cnt))\n        x = self.apply_conv(tmp)\n        x = Flatten()(x)\n        linear_input = x.shape[1]\n        # ------------------------------------------------------\n\n        self.fc1 = Dense(512, activation='relu')\n        self.bn5 = BatchNormalization()\n        self.fc2 = Dense(1024, activation='relu')\n        self.bn6 = BatchNormalization()\n        self.fc3 = Dense(512, activation='relu')\n        self.bn7 = BatchNormalization()\n        self.fc4 = Dense(2, activation='softmax')\n\n    def apply_conv(self, x):\n        x = activations.relu(self.conv1(x))\n        x = self.bn1(x)\n        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n        x = activations.relu(self.conv2(x))\n        x = self.bn2(x)\n        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n        x = activations.relu(self.conv3(x))\n        x = self.bn3(x)\n        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n        x = activations.relu(self.conv4(x))\n        x = self.bn4(x)\n        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n        return x\n\n    def call(self, x):\n        conv_out = self.apply_conv(x)\n        x = Flatten()(conv_out)\n        x = self.fc1(x)\n        x = self.bn5(x)\n        x = Dropout(0.4)(x)\n        x = self.fc2(x)\n        x = self.bn6(x)\n        x = Dropout(0.4)(x)\n        x = self.fc3(x)\n        x = self.bn7(x)\n        x = Dropout(0.4)(x)\n        x = self.fc4(x)\n        return x\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\n\nEPOCHS = 200\nSTEPS = 50\n\nwith tpu_strategy.scope():\n    net = BC3DConvNet(frame_cnt, frame_width)\n    net.compile(loss='binary_crossentropy', \n                optimizer=keras.optimizers.Adam(learning_rate=0.0005,weight_decay=0.15,clipnorm=1.0), \n                steps_per_execution=32,\n                metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = net.fit(combined_trn_dataset, epochs=EPOCHS, steps_per_epoch=STEPS, validation_data = combined_val_dataset, validation_steps=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plotting training and validation loss\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting training and validation loss\nplt.plot(history.history['loss'][50:], label='Training Loss')\nplt.plot(history.history['val_loss'][50:], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting training and validation loss\nplt.plot(history.history['loss'][:50], label='Training Loss')\nplt.plot(history.history['val_loss'][:50], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net.save_weights('BC3DConvNet', save_format='tf')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}